df = read.csv('realestate_data.csv')
df
#summary of the data set 
summary(df)

#here is to check the data charcteristics
str(df)
sapply(df, class)

#sum of the NA Values in the data set
sum(is.na(df))
#here we are seeing the names of the data set column names
colnames(df)



#here is the loop that is checking ,replacing and removing the NA values from the Data Frame

for (i in which(sapply(df, is.numeric))) {
  df[is.na(df[, i]), i] = mean(df[, i],  na.rm = TRUE)
}


#here is new data frame which  omitting the NA values here another technique the remove NA values from the data set 
newdf = na.omit(df)





#------------------------Rgression with single Variable--------------------------------



#declare the variable and get values from the data set seprately
x = df$sqft_living15 #its become the independent variable in leaning model
y = df$price  #its going to be predicted or dependent variable

# Apply the lm() function.
relation = lm(y~x)

#print the relation generated by the lm function and summary of the relation variable
print(relation)
print(summary(relation)) #R square value is 0.34 means it gives 34% of accuracy

#here is data and frame is two functions and having x variable with value of row of 'sqft_living15'
a = data.frame(x = 1340)
result =  predict(relation,a) #going to predict the price on the basis of sqft_living15 value 
print(result) 


#ploting the graph of the variable

# Give the chart file a name.
png(file = "linearregression.png")
# Plot the chart.
plot(y,x,col = "blue",main = "price  & sqft_living15",
     abline(lm(x~y)),cex = 1.3,pch = 16,xlab = "price",ylab = "sqft_living15")
# Save the file.
dev.off()


#------------------------Multiple Linear Regression--------------------------------

# 
# Following is the description of the parameters used âˆ’
# 
# y is the response variable.
# 
# a, b1, b2...bn are the coefficients.
# 
# x1, x2, ...xn are the predictor variables.
# 
# We create the regression model using the lm() function in R. The model determines the value of the coefficients using the input data. Next we can predict the value of the response variable for a given set of predictor variables using these coefficients.
# 
# lm() Function
# This function creates the relationship model between the predictor and the response variable.
# 
# Syntax
# The basic syntax for lm() function in multiple regression is




colnames(df)
new_df = df[,c("price","bedrooms","bathrooms","sqft_living","sqft_lot","floors","waterfront","view","condition","grade","sqft_above","yr_built","sqft_living15","sqft_lot15")]
model <- lm(price~bedrooms+bathrooms+sqft_living+sqft_lot+floors+waterfront+view+condition+grade+sqft_above+yr_built+sqft_living15+sqft_lot15, data = new_df)
summary(model) #here Rsquared is 65%
# Show the model.
model

cat("# # # # The Coefficient Values # # # ","\n")
Xprice = coef(model)[1]
print(Xprice)
Xbedrooms = coef(model)[2]
print(Xbedrooms)
Xbathrooms = coef(model)[3]
print(Xbathrooms)
Xsqft_living = coef(model)[4]
print(Xsqft_living)
Xsqft_lot = coef(model)[5]
print(Xsqft_lot)
Xfloors = coef(model)[6]
print(Xfloors)
Xwaterfront = coef(model)[7]
print(Xwaterfront)
Xview = coef(model)[8]
print(Xview)
Xcondition = coef(model)[9]
print(Xcondition)
Xgrade = coef(model)[10]
print(Xgrade)
Xsqft_above = coef(model)[11]
print(Xsqft_above)
Xsqft_basement = coef(model)[12]
print(Xsqft_basement)
Xyr_built = coef(model)[13]
print(Xyr_built)
Xsqft_living15 = coef(model)[14]
print(Xsqft_living15)
Xsqft_lot15 = coef(model)[15]
print(Xsqft_lot15)
 
# Y = a+Xdisp.x1+Xhp.x2+Xwt.x3
# here is the formula

Y=(6311960.373850)+(-39458.662313)*3+(46937.370742)*1.0+(46937.370742)*1180+(46937.370742)*5650+(167.009569)*1.0+(-0.002682)*0+(27258.818309)*0+(581782.787088)*3+(43398.984884)*7+(18442.412429)*1180+(119845.393906)*1955+(-6.128757)*1340+(-3628.578851)*560

Y

cat(sprintf("\"%f\" \"%f\"\"%f\" \"%f\"\"%f\" \"%f\"\"%f\" \"%f\"\"%f\" \"%f\"\"%f\" \"%f\"\"%f\"\n",Xprice,Xbedrooms,Xbathrooms,Xsqft_living,Xsqft_lot,Xfloors,Xwaterfront,Xview,Xcondition,Xgrade,Xsqft_above,Xsqft_basement,Xyr_built,Xsqft_living15,Xsqft_lot15))






#-------------Multiple Regression--------------

#dividing data into train and test set 

# 80% of the sample size
smp_size <- floor(0.8 * nrow(df))

## set the seed to make your partition reproducible
set.seed(123)
train <- sample(seq_len(nrow(df)), size = smp_size)

training_data <- df[train_, ]
testing_data <- df[-train_, ]

relation_1 <- lm(price~sqft_living15,data=training_data)

summary(relation_1)


relation_2 <- lm(price~sqft_living,data=training_data)

summary(relation_2)

#residual standard error  is Standard deviation of residual 
#Multiple R- squared is percentage of variance 

relation <- lm(price~bedrooms+bathrooms+sqft_living+sqft_lot+floors+waterfront+view+condition+grade+sqft_above+yr_built+sqft_living15+sqft_lot15, data=training_data)

summary(relation)

print(relation)

confint(relation)


predictions = predict.lm(relation, testing_data)

predictions

RMS = mean(predictions-testing_data$price)^2 #Root mean square 

print('Residual Error (MSE): ')
RMS

plot(relation)


#seprate the categorical variables
unique(df$view)
df$view
unique(df$grade)
max(df$grade)
unique(df$condition)
df$condition

table(df$view)


#----------------------Logistic Regression---------------------------
# Table outcome
table(df$condition)

# Baseline accuracy
98/131

# Install and load caTools package
install.packages("caTools")
library(caTools)

# Randomly split data
set.seed(88)
split = sample.split(df$price, SplitRatio = 0.75)
split

# Create training and testing sets
qualityTrain = subset(df, split == TRUE)
qualityTest = subset(df, split == FALSE)

# Logistic Regression Model
QualityLog = glm(df$condition~, data=qualityTrain)
summary(QualityLog)

# Make predictions on training set
predictTrain = predict(QualityLog, type="response")

predictTrain

# Analyze predictions
summary(predictTrain)
tapply(predictTrain, qualityTrain$PoorCare, mean)


# Confusion matrix for threshold of 0.5
table(qualityTrain$PoorCare, predictTrain > 0.5)

# Sensitivity and specificity
10/25
70/74

# Confusion matrix for threshold of 0.7
table(qualityTrain$PoorCare, predictTrain > 0.7)

# Sensitivity and specificity
8/25
73/74

# Confusion matrix for threshold of 0.2
table(qualityTrain$PoorCare, predictTrain > 0.2)

# Sensitivity and specificity
16/25
54/74


install.packages("Amelia")
library(Amelia)
missmap(df, main = "Missing values vs observed")

